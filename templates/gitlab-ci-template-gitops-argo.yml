# Available here https://raw.githubusercontent.com/sparkfabrik/spark-k8s-deployer/task/gitops_argocd_pipeline_template/templates/gitlab-ci-template-gitops-argo.yml
image: ghcr.io/sparkfabrik/spark-k8s-deployer:latest

stages:
  - populate cache
  - build
  - sync
  - configure deploy
  - deploy

variables:
  # Following variables must be exposed as CI/CD variables (preferably as group variables since they are shared).
  #   ARGOCD_APP_OF_APPS_AUTH_TOKEN
  #   ARGOCD_APP_OF_APPS_NAME
  #   ARGOCD_AUTH_TOKEN
  #   CI_PROJECT_ROOT_NAMESPACE
  #   GCLOUD_PROJECT_NAME
  #   KANIKO_SERVICE_ACCOUNT
  #   KUBE_INGRESS_BASE_DOMAIN
  #   ENVIRONMENT_SCOPE_PREFIX - used to set the active kube config, default to "review"

  #   AUTOMATION_REPO_ACCESS_TOKEN
  #   AUTOMATION_REPO_BASE_URL
  #   DB_HOST: private CloudSQL IP address
  #   DB_USER
  #   DB_PASS
  #   S3_ACCESS_KEY: HMAC autentication key
  #   S3_HOST
  #   S3_PUBLIC_FOLDER
  #   S3_REGION
  #   S3_SECRET_KEY: HMAC autentication secret

  # Following variables must be exposed as Gitlab CI/CD variables in the single app code repo.
  #   INFRASTRUCTURE_REPO_BASE_URL
  #   INFRASTRUCTURE_REPO_ACCESS_TOKEN
  #   MAILGUN_API_KEY
  #   MAILGUN_WORKING_DOMAIN

  ARGOCD_PROJECT_SLUG: ${GCLOUD_PROJECT_NAME}
  ARGOCD_APP_NAME: ${CI_PROJECT_NAME}-${CI_COMMIT_REF_SLUG}

  AUTOMATION_REPO_GIT_URL: https://${AUTOMATION_REPO_ACCESS_TOKEN}@${AUTOMATION_REPO_BASE_URL}
  INFRASTRUCTURE_REPO_GIT_URL: https://${INFRASTRUCTURE_REPO_ACCESS_TOKEN}@${INFRASTRUCTURE_REPO_BASE_URL}

  AUTOMATION_REPO_DIR: ${CI_PROJECT_DIR}/automation
  INFRASTRUCTURE_REPO_DIR: ${CI_PROJECT_DIR}/infrastructure

  KUBE_NAMESPACE: ${CI_PROJECT_ROOT_NAMESPACE}-${CI_PROJECT_NAME}-${CI_COMMIT_REF_SLUG}
  ENVIRONMENT_SCOPE_PREFIX: review

  CI_REGISTRY_IMAGE_PHP: eu.gcr.io/${GCLOUD_PROJECT_NAME}/${CI_PROJECT_ROOT_NAMESPACE}-${CI_PROJECT_NAME}-php
  CI_REGISTRY_IMAGE_NGINX: eu.gcr.io/${GCLOUD_PROJECT_NAME}/${CI_PROJECT_ROOT_NAMESPACE}-${CI_PROJECT_NAME}-nginx

  CI_ENVIRONMENT_BASE_URL: ${CI_COMMIT_REF_SLUG}.${CI_PROJECT_NAME}.${KUBE_INGRESS_BASE_DOMAIN}

  # ------
  # PROJECT SPECIFIC VARS

  DRUPAL_TRUSTED_HOST: ${CI_COMMIT_REF_SLUG}\.${CI_PROJECT_NAME}\.${KUBE_INGRESS_BASE_DOMAIN}

  DB_NAME: ${CI_PROJECT_NAME}_${CI_COMMIT_REF_SLUG}
  DB_PORT: 3306

  S3_BUCKET: ${CI_PROJECT_ROOT_NAMESPACE}-${CI_PROJECT_NAME}-${CI_COMMIT_REF_SLUG}

# Pipelines runs only for stage and production branches.
#
# This also remove duplicated detached pipeline created with a merge
# request or when adding a tag.
workflow:
  rules:
    - if: '$CI_COMMIT_REF_SLUG == "stage" || $CI_COMMIT_REF_SLUG == "production"'
      when: always
    - when: never

cache: &global_cache
  key: "${CI_COMMIT_SHORT_SHA}"
  paths:
    - ${AUTOMATION_REPO_DIR}
  policy: pull

# --------------
# POPULATE CACHE
# --------------
clone automation repo:
  stage: populate cache
  script:
    # Clone automation repo and store his files for next build step using Kaniko.
    - git clone ${AUTOMATION_REPO_GIT_URL} ${AUTOMATION_REPO_DIR}
    - cd ${AUTOMATION_REPO_DIR}
    - git checkout master --
  cache:
    # inherit all global cache settings
    <<: *global_cache
    # override the policy
    policy: push
  artifacts:
    expire_in: 60 mins
    paths:
      - ${AUTOMATION_REPO_DIR}

# --------------
# BUILD
# --------------
nginx:
  stage: build
  image:
    # Use debug image because we need a shell (ref. Gitlab docs)
    name: gcr.io/kaniko-project/executor:debug
    entrypoint: [""]
  script:
    # Set gcr.io credentials. Don't use /tmp because multistage builds will destroy FS across stages.
    - mkdir -p /kaniko/.gcr; echo -n ${KANIKO_SERVICE_ACCOUNT} | base64 -d > /kaniko/.gcr/sa.json
    - export GOOGLE_APPLICATION_CREDENTIALS=/kaniko/.gcr/sa.json
    # Build and push image using Kaniko executor.
    - /kaniko/executor
      --context ${CI_PROJECT_DIR}
      --dockerfile ${AUTOMATION_REPO_DIR}/docker/images/nginx/Dockerfile
      --destination ${CI_REGISTRY_IMAGE_NGINX}:${CI_COMMIT_SHA}
      --destination ${CI_REGISTRY_IMAGE_NGINX}:${CI_COMMIT_REF_SLUG}
      --destination ${CI_REGISTRY_IMAGE_NGINX}:latest

php:
  stage: build
  image:
    # Use debug image because we need a shell (ref. Gitlab docs)
    name: gcr.io/kaniko-project/executor:debug
    entrypoint: [""]
  script:
    # Set gcr.io credentials. Don't use /tmp because multistage builds will destroy FS across stages
    # IMPORTANT: use a dedicated service account with limited scope.
    - mkdir -p /kaniko/.gcr; echo -n ${KANIKO_SERVICE_ACCOUNT} | base64 -d > /kaniko/.gcr/sa.json
    - export GOOGLE_APPLICATION_CREDENTIALS=/kaniko/.gcr/sa.json
    # Build and push image using Kaniko executor.
    - /kaniko/executor
      --context ${CI_PROJECT_DIR}
      --dockerfile ${AUTOMATION_REPO_DIR}/docker/images/php/Dockerfile
      --destination ${CI_REGISTRY_IMAGE_PHP}:${CI_COMMIT_SHA}
      --destination ${CI_REGISTRY_IMAGE_PHP}:${CI_COMMIT_REF_SLUG}
      --destination ${CI_REGISTRY_IMAGE_PHP}:latest

# --------------
# SYNC TO GITOPS REPO
# --------------
sync to infrastructure repo:
  stage: sync
  script:
    # Init Helm 3.
    - helm3 repo add "stable" "https://charts.helm.sh/stable"
    - helm3 repo add "sparkfabrik" "https://storage.googleapis.com/spark-helm-charts"
    - helm3 repo update
    # Clone environment repo.
    - mkdir -p ${INFRASTRUCTURE_REPO_DIR}
    - cd ${INFRASTRUCTURE_REPO_DIR}
    - git config --global user.email "gitlab-bot@sparkfabrik.com"
    - git config --global user.name "Gitlab Bot"
    - git clone ${INFRASTRUCTURE_REPO_GIT_URL} .
    # Switch on current feature branch (stage or production, see current job rules).
    - git checkout -B ${CI_COMMIT_REF_SLUG} --
    # Clean generated manifests dir to start from a clean state and remove deprecated manifests.
    - rm -rf ${INFRASTRUCTURE_REPO_DIR}/generated-manifests
    # Generate updated manifests. Automation repo was cached in a previous build job.
    - envsubst < ${AUTOMATION_REPO_DIR}/docker/helm/values.${CI_COMMIT_REF_SLUG}.yaml.tpl > ${INFRASTRUCTURE_REPO_DIR}/values.yaml
    - helm3 template ${CI_PROJECT_NAME}-${CI_COMMIT_REF_SLUG} sparkfabrik/drupal
      -f ${INFRASTRUCTURE_REPO_DIR}/values.yaml
      --version 4.8.0
      --render-subchart-notes
      --output-dir ${INFRASTRUCTURE_REPO_DIR}/generated-manifests
      --include-crds
      --wait
    # Commit updated manifests to the repo.
    - git add .
    # @TODO: find a better solution than allow-empty flag to prevent push to repo when we do not have changes.
    - git commit -a -m "${CI_PROJECT_TITLE} release on branch ${CI_COMMIT_REF_SLUG}@${CI_COMMIT_SHORT_SHA}" --allow-empty
    - git push -u origin ${CI_COMMIT_REF_SLUG}

# --------------
# CONFIGURE ARGO
# --------------
# Push argocd crd manifest to the automation repo and update the app of apps.
configure deploy:
  stage: configure deploy
  environment:
    # This section is needed only to populate the CI_ENVIRONMENT_SLUG variable
    # we are in Helm values.
    name: ${CI_COMMIT_REF_SLUG}
  script:
    # Configure Argo CD cli
    - export ARGOCD_SERVER='argocd-server.argocd.svc.cluster.local'
    - export ARGOCD_OPTS='--insecure'
    - export ARGOCD_AUTH_TOKEN=${ARGOCD_APP_OF_APPS_AUTH_TOKEN}
    # Download Argo CD cli
    # We download argo CD cli from server instead of retrieve the version from official git repo. This is better, since
    # the cli will always be compatible with the server (same version).
    - curl -sSL --insecure -o /usr/local/bin/argocd http://${ARGOCD_SERVER}/download/argocd-linux-amd64
    - chmod +x /usr/local/bin/argocd
    # Clone repo, generate ArgoCD application CRD and push the manifest to the repo.
    - git config --global user.email "gitlab-bot@sparkfabrik.com"
    - git config --global user.name "Gitlab Bot"
    - cd ${AUTOMATION_REPO_DIR}
    - git fetch -p && git reset --hard origin/master
    - mkdir -p argocd-app-crds
    - envsubst < ${AUTOMATION_REPO_DIR}/docker/argocd/application.yaml.tpl > ${AUTOMATION_REPO_DIR}/argocd-app-crds/${ARGOCD_APP_NAME}.yaml
    # Commit generated crd manifest to the repo.
    - git add .
    # @TODO: we should commit and push only if we have a diff.
    - git commit -a -m "${CI_PROJECT_TITLE} release on branch ${CI_COMMIT_REF_SLUG}@${CI_COMMIT_SHORT_SHA}" --allow-empty
    - git push -u origin master
    # Trigger sync on the app of apps ArgoCD project.
    - argocd app sync ${ARGOCD_APP_OF_APPS_NAME}
    - argocd app wait ${ARGOCD_APP_OF_APPS_NAME}
  rules:
    - if: '$CI_COMMIT_REF_SLUG == "stage" || $CI_COMMIT_REF_SLUG == "production"'
      when: on_success
    - when: never

# --------------
# DEPLOY APP USING ARGO SYNC
# --------------
# See https://argoproj.github.io/argo-cd/user-guide/ci_automation/ for reference.
argo sync:
  stage: deploy
  environment:
    name: ${ENVIRONMENT_SCOPE_PREFIX}/${CI_COMMIT_REF_SLUG}
    url: https://${CI_COMMIT_REF_SLUG}.${CI_PROJECT_NAME}.${KUBE_INGRESS_BASE_DOMAIN}
    kubernetes:
      namespace: ${KUBE_NAMESPACE}
  script:
    # Configure Argo CD cli
    # NOTE: ARGOCD_AUTH_TOKEN env var must be set in Gitlab CI
    - export ARGOCD_SERVER='argocd-server.argocd.svc.cluster.local'
    - export ARGOCD_OPTS='--insecure'
    # Download Argo CD cli
    # We download argo CD cli from server instead of retrieve the version from official git repo. This is better, since
    # the cli will always be compatible with the server (same version).
    - curl -sSL --insecure -o /usr/local/bin/argocd http://${ARGOCD_SERVER}/download/argocd-linux-amd64
    - chmod +x /usr/local/bin/argocd
    # Stream pod logs.
    - mkdir -p "${CI_PROJECT_DIR}/logs"
    - stern "${CI_PROJECT_NAME}-${CI_COMMIT_REF_SLUG}" --namespace "${KUBE_NAMESPACE}"
      --color never --tail=1 --exclude "[^""]*""[^""]*""\s[2-3]{1}[0-9]{2}"
      -l pipeline_id="${CI_PIPELINE_ID}" | tee "${CI_PROJECT_DIR}/logs/application.logs" &
    # Sync app
    - argocd app sync ${CI_PROJECT_NAME}-${CI_COMMIT_REF_SLUG}
    - argocd app wait ${CI_PROJECT_NAME}-${CI_COMMIT_REF_SLUG}
  artifacts:
    when: always
    expire_in: 1 week
    paths:
      - ${CI_PROJECT_DIR}/logs
